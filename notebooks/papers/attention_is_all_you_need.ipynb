{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention is All You Need\n",
    "\n",
    "This notebook is an implementation of a transformer model introduced in the paper \"Attention is all you need\" [1]. The model is trained on a small dataset of Pink Floyd lyrics [2]. The first version consists of decoder-only model, trained on a language modeling task. The second version consists of full encoder-decoder style architecture, where the encoder processes song titles, and the decoder is trained to predict the lyrics.\n",
    "\n",
    "### References\n",
    "\n",
    "1. A. Vaswani et al., “Attention Is All You Need.” arXiv, Dec. 05, 2017. doi: 10.48550/arXiv.1706.03762.\n",
    "2. J. Robson, \"Pink Floyd Lyrics\", retrieved from [url](https://www.kaggle.com/datasets/joaorobson/pink-floyd-lyrics/code).\n",
    "3. R. Sennrich, B. Haddow, A. Birch, \"Neural Machine Translation of Rare WOrds with Subword Units\", 2016. doi: 10.48550/arXiv.1508.07909"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Tokenization\n",
    "\n",
    "We start by preprocessing the dataset and training a tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>song_title</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Astronomy Domine</td>\n",
       "      <td>1967-08-05</td>\n",
       "      <td>\"Moon in both [houses]...\"...Scorpio, [Arabian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Lucifer Sam</td>\n",
       "      <td>1967-08-05</td>\n",
       "      <td>Lucifer Sam, siam cat\\nAlways sitting by your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Matilda Mother</td>\n",
       "      <td>1967-08-05</td>\n",
       "      <td>There was a king who ruled the land\\nHis Majes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Flaming</td>\n",
       "      <td>1967-08-05</td>\n",
       "      <td>Alone in the clouds all blue\\nLying on an eide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Piper at the Gates of Dawn</td>\n",
       "      <td>Pow R. Toc H.</td>\n",
       "      <td>1967-08-05</td>\n",
       "      <td>TCH TCH\\nAHH (AHH)\\nTCH TCH\\nAHH AHH\\nDoi doi\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            album        song_title        year  \\\n",
       "0  The Piper at the Gates of Dawn  Astronomy Domine  1967-08-05   \n",
       "1  The Piper at the Gates of Dawn       Lucifer Sam  1967-08-05   \n",
       "2  The Piper at the Gates of Dawn    Matilda Mother  1967-08-05   \n",
       "3  The Piper at the Gates of Dawn           Flaming  1967-08-05   \n",
       "4  The Piper at the Gates of Dawn     Pow R. Toc H.  1967-08-05   \n",
       "\n",
       "                                              lyrics  \n",
       "0  \"Moon in both [houses]...\"...Scorpio, [Arabian...  \n",
       "1  Lucifer Sam, siam cat\\nAlways sitting by your ...  \n",
       "2  There was a king who ruled the land\\nHis Majes...  \n",
       "3  Alone in the clouds all blue\\nLying on an eide...  \n",
       "4  TCH TCH\\nAHH (AHH)\\nTCH TCH\\nAHH AHH\\nDoi doi\\...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./assets/data/pink_floyd_lyrics.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We additionally exclude two albums involving Syd Barrett, in order to obtain a more coherent corpus that resembles more of a later style of Pink Floyd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data[\"album\"].isin([\"The Piper at the Gates of Dawn\", \"A Saucerful of Secrets\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Cleaning\n",
    "\n",
    "This version of the dataset is quite noisy and contains lots of unformatted lyrics (see e.g. [Pink Floyd dataset of Huggingface](https://huggingface.co/datasets/huggingartists/pink-floyd) for a more cleaned up version). To compensate for this, we next perform some data preparation and cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(columns=[\"album\", \"year\"])\n",
    "df = df.dropna()\n",
    "\n",
    "df = df.replace(\"\\((.*?)\\),? ?\", \"\", regex=True)   # remove round brackets and content\n",
    "df = df.replace(\"\\[(.*?)\\],? ?\", \"\", regex=True)   # remove round brackets and content\n",
    "df = df.replace(\"[\\\"“”…]\", \"\", regex=True)         # remove \"\n",
    "df = df.replace(\"\\.{3,}\", \"...\", regex=True)       # replace multiple dots with three dots\n",
    "df = df.replace(\"(\\*.*\\*)\", \"\", regex=True)        # remove sound effects between *\n",
    "df = df.replace(\"[\\:\\-\\.\\!\\?]\", \" \", regex=True)   # remove :, -, ., !, ?\n",
    "df = df.replace(\"\\\\\\\\ n\", \"\\n\", regex=True)        # remove ill-formatted newlines\n",
    "df = df.replace(\"\\\\\\\\\", \"\", regex=True)            # remove \\\n",
    "df = df.replace(\"(\\\\n)+\", \"\\\\n\", regex=True)       # remove multiple newlines\n",
    "df = df.replace(\" +\", \" \", regex=True)             # remove multiple spaces\n",
    "df = df.replace(\"\\n \", \"\\n\", regex=True)           # remove leading spaces after newline\n",
    "\n",
    "df[\"lyrics\"] = df[\"lyrics\"].str.lower()            # lowercase\n",
    "df[\"lyrics\"] = df[\"lyrics\"].str.strip(\"-. \")       # remove leading and trailing spaces\n",
    "df[\"lyrics\"] = df[\"lyrics\"].str.replace(\"\\\\n\", \" \", regex=True)\n",
    "\n",
    "df[\"song_title\"] = df[\"song_title\"].str.lower() \n",
    "df[\"song_title\"] = df[\"song_title\"].str.strip(\"-. \")\n",
    "\n",
    "lyrics = [l for l in df.lyrics]\n",
    "lyrics = \"[BOS]\".join(lyrics)                      # add BOS token between songs\n",
    "titles = \"[BOS]\".join([t for t in df.song_title])\n",
    "\n",
    "with open(\"./assets/data/pink_floyd_lyrics.txt\", \"w\") as f: f.write(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Next, we tokenize the obtained lyrics and titles. Following the original paper, we will utilize byte-pair encoding [3]. We additionally introduce two special tokens. First, the `[BOS]` token indicates the beginning of each song. Second, the `[PAD]` token is used when padding batch during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, normalizers\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.normalizers import NFD, Lowercase, Strip, StripAccents\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(BPE())\n",
    "tokenizer.normalizer = normalizers.Sequence([NFD(), StripAccents(), Lowercase(), Strip()])\n",
    "tokenizer.pre_tokenizer = Whitespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 4155\n"
     ]
    }
   ],
   "source": [
    "trainer = BpeTrainer(special_tokens=[\"[BOS]\", \"[PAD]\"], show_progress=False)\n",
    "tokenizer.train_from_iterator([lyrics + titles], trainer=trainer)\n",
    "print(f\"Vocabulary Size: {tokenizer.get_vocab_size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "With a trained tokenizer, we turn our attention to the model. The definition of transformer is found in the `microai.models.transformer` module. Because we are working with a very small dataset, we also scale down the size of the model accordingly.\n",
    "\n",
    "### Training Setup\n",
    "\n",
    "In this section, we prepare the model for training and evaluation pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microai.models.transformer import TransformerConfig, Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All model-related parameters are encapsulated in a `TransformerConfig` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TransformerConfig(\n",
    "    style=\"decoder\",\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    "    d_model=64,\n",
    "    num_heads=8,\n",
    "    context_size=128,\n",
    "    dropout=0.2,\n",
    "    decoder_layers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, the model itself can be instantiated from the created config. We additionally define few of the parameters used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "batch_size = 32\n",
    "epochs = 2000\n",
    "eval_freq = 50\n",
    "weight_decay = 1e-2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(config).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight decay is applied to linear layers, but not biases and other 1D params (e.g., in layer normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {k: v for k, v in model.named_parameters() if v.requires_grad}\n",
    "\n",
    "params_decay = [v for _, v in params.items() if v.dim() >= 2]\n",
    "params_no_decay = [v for _, v in params.items() if v.dim() < 2]\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": params_decay, \"weight_decay\": weight_decay},\n",
    "    {\"params\": params_no_decay, \"weight_decay\": 0.0}\n",
    "], lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions\n",
    "\n",
    "Here, we group few of the utility functions used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(tokens: List[List[int]], batch_size: int):\n",
    "    def _pad(sequence: List[int], size: int):\n",
    "        return [tokenizer.token_to_id(\"[BOS]\")] * (size - len(sequence)) + sequence\n",
    "    \n",
    "    ids = torch.randperm(len(tokens))[:batch_size].tolist()\n",
    "    input = [tokens[i] for i in range(len(tokens)) if i in ids]\n",
    "    max_size = max([len(i) for i in input])\n",
    "    input = [_pad(i, max_size) for i in input]\n",
    "    input = torch.tensor(input, device=device)\n",
    "\n",
    "    return input[:, :-1], input[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(tokens: List[List[int]], batch_size: int = 5, num_batches: int = 25):\n",
    "    losses = []\n",
    "    \n",
    "    for _ in range(num_batches):\n",
    "        x, y = get_batch(tokens, batch_size=batch_size)\n",
    "\n",
    "        y_pred = model(x)\n",
    "        loss = F.cross_entropy(y_pred.view((-1, y_pred.size(-1))), y.view(-1))\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data: pd.DataFrame, context_size: int, encode_song_title: bool = False):\n",
    "    items = []\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        tokens = tokenizer.encode(row[\"lyrics\"]).ids\n",
    "        title_tokens = tokenizer.encode(row[\"song_title\"]).ids\n",
    "\n",
    "        for batch in range(len(tokens) // context_size + 1):\n",
    "            item_tokens = tokens[batch * context_size: (batch + 1) * context_size]\n",
    "            item = (title_tokens, item_tokens) if encode_song_title else item_tokens\n",
    "            items.append(item)\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens\n",
    "\n",
    "The training portion of the dataset is comprised of $90\\%$ of available tokens, where $10\\%$ is left for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize_data(df, config.context_size)\n",
    "\n",
    "train_chunk = 0.9\n",
    "train_ids = torch.randperm(len(tokens))[:int(len(tokens) * train_chunk)].tolist()\n",
    "\n",
    "train_tokens = [tokens[i] for i in range(len(tokens)) if i in train_ids]\n",
    "test_tokens = [tokens[i] for i in range(len(tokens)) if i not in train_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We train the mode for 2000 epochs, evaluating the train/test loss every 50 epochs using a held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 10.188, Test Loss: 9.912\n",
      "Epoch: 50, Train Loss: 5.298, Test Loss: 4.907\n",
      "Epoch: 100, Train Loss: 5.022, Test Loss: 4.531\n",
      "Epoch: 150, Train Loss: 4.546, Test Loss: 4.525\n",
      "Epoch: 200, Train Loss: 4.376, Test Loss: 3.997\n",
      "Epoch: 250, Train Loss: 4.408, Test Loss: 4.140\n",
      "Epoch: 300, Train Loss: 3.971, Test Loss: 3.803\n",
      "Epoch: 350, Train Loss: 3.975, Test Loss: 3.813\n",
      "Epoch: 400, Train Loss: 4.006, Test Loss: 3.732\n",
      "Epoch: 450, Train Loss: 3.625, Test Loss: 3.910\n",
      "Epoch: 500, Train Loss: 3.893, Test Loss: 3.877\n",
      "Epoch: 550, Train Loss: 3.605, Test Loss: 3.954\n",
      "Epoch: 600, Train Loss: 3.722, Test Loss: 3.903\n",
      "Epoch: 650, Train Loss: 3.586, Test Loss: 3.800\n",
      "Epoch: 700, Train Loss: 3.834, Test Loss: 3.810\n",
      "Epoch: 750, Train Loss: 3.367, Test Loss: 3.959\n",
      "Epoch: 800, Train Loss: 3.513, Test Loss: 3.693\n",
      "Epoch: 850, Train Loss: 3.435, Test Loss: 4.001\n",
      "Epoch: 900, Train Loss: 3.452, Test Loss: 3.803\n",
      "Epoch: 950, Train Loss: 3.655, Test Loss: 3.967\n",
      "Epoch: 1000, Train Loss: 3.514, Test Loss: 3.845\n",
      "Epoch: 1050, Train Loss: 3.820, Test Loss: 3.812\n",
      "Epoch: 1100, Train Loss: 3.326, Test Loss: 3.905\n",
      "Epoch: 1150, Train Loss: 3.403, Test Loss: 3.915\n",
      "Epoch: 1200, Train Loss: 3.573, Test Loss: 3.853\n",
      "Epoch: 1250, Train Loss: 3.346, Test Loss: 3.825\n",
      "Epoch: 1300, Train Loss: 3.641, Test Loss: 3.783\n",
      "Epoch: 1350, Train Loss: 3.535, Test Loss: 3.981\n",
      "Epoch: 1400, Train Loss: 3.695, Test Loss: 3.882\n",
      "Epoch: 1450, Train Loss: 3.764, Test Loss: 3.723\n",
      "Epoch: 1500, Train Loss: 3.491, Test Loss: 4.014\n",
      "Epoch: 1550, Train Loss: 3.505, Test Loss: 3.498\n",
      "Epoch: 1600, Train Loss: 3.554, Test Loss: 3.700\n",
      "Epoch: 1650, Train Loss: 3.540, Test Loss: 3.729\n",
      "Epoch: 1700, Train Loss: 3.444, Test Loss: 3.952\n",
      "Epoch: 1750, Train Loss: 3.554, Test Loss: 3.812\n",
      "Epoch: 1800, Train Loss: 3.264, Test Loss: 3.741\n",
      "Epoch: 1850, Train Loss: 3.644, Test Loss: 3.544\n",
      "Epoch: 1900, Train Loss: 3.423, Test Loss: 3.914\n",
      "Epoch: 1950, Train Loss: 3.385, Test Loss: 3.665\n",
      "Epoch: 2000, Train Loss: 3.548, Test Loss: 3.949\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    x, y = get_batch(train_tokens, batch_size=batch_size)\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    y_pred = model(x)\n",
    "    loss = F.cross_entropy(y_pred.view((-1, y_pred.size(-1))), y.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % eval_freq == 0 or epoch == 1:\n",
    "        train_loss, test_loss = estimate_loss(train_tokens), estimate_loss(test_tokens)\n",
    "        print(f\"Epoch: {epoch}, Train Loss: {train_loss:.3f}, Test Loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "To evaluate the model, we prompt it with few words and ask it to continue the sequence, up to a predefined maximum length. The results are far from perfect, but the model has learned basic relationships between words and does produce \"Pink Floyd like\" sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model: Transformer, prompt: str, context_size: int = 8, max_length: int = 1000):\n",
    "    context = torch.tensor(tokenizer.encode(prompt).ids, device=device)\n",
    "    model.eval()\n",
    "\n",
    "    while True:    \n",
    "        logits = model(context[-context_size:].unsqueeze(0))\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        token = torch.multinomial(probs[:, -1, :].flatten(), num_samples=1).item()\n",
    "        if context.size(0) >= max_length:\n",
    "            break\n",
    "        context = torch.cat((context, torch.tensor([token], device=device)), dim=0)\n",
    "\n",
    "    model.train()\n",
    "    return tokenizer.decode(context.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shine on ground to make the weak in the animals become the lived now at\n",
      "time has the same we lie out is who for all anced ’ s are\n",
      "money you want and high is in you feel narrow hey you ’ ll to\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, \"shine on \", context_size=config.context_size, max_length=15))\n",
    "print(generate(model, \"time \", context_size=config.context_size, max_length=15))\n",
    "print(generate(model, \"money \", context_size=config.context_size, max_length=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-Decoder Structure\n",
    "\n",
    "To provide a proof-of-concept that involves a full encoder-decoder structure of the transformer, we will continue to do language modeling, but now conditioned on the title of a song, which will be passed through the encoding layers of the model. This is a very crude task to train a model on, but it will serve a purpose of demonstrating the full transformer architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions\n",
    "\n",
    "Like before, we group few of the utility functions used throughout training. The only difference to previous version is the incorporation of song title into the model's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_with_titles(tokens: List[Tuple[List[int], List[int]]], batch_size: int):\n",
    "    def _pad(sequence: List[int], size: int):\n",
    "        return [tokenizer.token_to_id(\"[PAD]\")] * (size - len(sequence)) + sequence\n",
    "    \n",
    "    ids = torch.randperm(len(tokens))[:batch_size].tolist()\n",
    "\n",
    "    # extract and pad lyrics\n",
    "    lyrics = [tokens[i][1] for i in range(len(tokens)) if i in ids]\n",
    "    max_size = max([len(i) for i in lyrics])\n",
    "    lyrics = [_pad(i, max_size) for i in lyrics]\n",
    "\n",
    "    # extract and pad titles\n",
    "    titles = [tokens[i][0] for i in range(len(tokens)) if i in ids]\n",
    "    titles = [_pad(i, max_size - 1) for i in titles]\n",
    "\n",
    "    lyrics = torch.tensor(lyrics, device=device)\n",
    "    titles = torch.tensor(titles, device=device)\n",
    "    return titles, lyrics[:, :-1], lyrics[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss_with_titles(tokens: List[Tuple[List[int], List[int]]], batch_size: int = 5, num_batches: int = 25):\n",
    "    losses = []\n",
    "    \n",
    "    for _ in range(num_batches):\n",
    "        titles, lyrics, targets = get_batch_with_titles(tokens, batch_size=batch_size)\n",
    "\n",
    "        y_pred = model((titles, lyrics))\n",
    "        loss = F.cross_entropy(y_pred.view((-1, y_pred.size(-1))), targets.flatten())\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Next, we initialize and train the full transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TransformerConfig(\n",
    "    style=\"encoder-decoder\",\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    "    d_model=64,\n",
    "    num_heads=2,\n",
    "    context_size=128,\n",
    "    dropout=0.1,\n",
    "    decoder_layers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize_data(df, config.context_size, encode_song_title=True)\n",
    "\n",
    "train_chunk = 0.9\n",
    "train_ids = torch.randperm(len(tokens))[:int(len(tokens) * train_chunk)].tolist()\n",
    "\n",
    "train_tokens = [tokens[i] for i in range(len(tokens)) if i in train_ids]\n",
    "test_tokens = [tokens[i] for i in range(len(tokens)) if i not in train_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "batch_size = 32\n",
    "epochs = 2000\n",
    "eval_freq = 50\n",
    "weight_decay = 1e-2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {k: v for k, v in model.named_parameters() if v.requires_grad}\n",
    "\n",
    "params_decay = [v for _, v in params.items() if v.dim() >= 2]\n",
    "params_no_decay = [v for _, v in params.items() if v.dim() < 2]\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": params_decay, \"weight_decay\": weight_decay},\n",
    "    {\"params\": params_no_decay, \"weight_decay\": 0.0}\n",
    "], lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 8.757, Test Loss: 8.629\n",
      "Epoch: 50, Train Loss: 5.182, Test Loss: 4.173\n",
      "Epoch: 100, Train Loss: 4.440, Test Loss: 4.131\n",
      "Epoch: 150, Train Loss: 4.546, Test Loss: 4.155\n",
      "Epoch: 200, Train Loss: 4.240, Test Loss: 3.441\n",
      "Epoch: 250, Train Loss: 4.371, Test Loss: 3.543\n",
      "Epoch: 300, Train Loss: 3.858, Test Loss: 3.774\n",
      "Epoch: 350, Train Loss: 3.776, Test Loss: 3.707\n",
      "Epoch: 400, Train Loss: 3.962, Test Loss: 3.251\n",
      "Epoch: 450, Train Loss: 3.790, Test Loss: 3.554\n",
      "Epoch: 500, Train Loss: 3.648, Test Loss: 3.443\n",
      "Epoch: 550, Train Loss: 3.725, Test Loss: 3.408\n",
      "Epoch: 600, Train Loss: 3.812, Test Loss: 3.545\n",
      "Epoch: 650, Train Loss: 3.725, Test Loss: 3.586\n",
      "Epoch: 700, Train Loss: 3.642, Test Loss: 3.700\n",
      "Epoch: 750, Train Loss: 3.745, Test Loss: 3.229\n",
      "Epoch: 800, Train Loss: 3.643, Test Loss: 3.934\n",
      "Epoch: 850, Train Loss: 3.681, Test Loss: 3.469\n",
      "Epoch: 900, Train Loss: 3.675, Test Loss: 3.214\n",
      "Epoch: 950, Train Loss: 3.653, Test Loss: 3.553\n",
      "Epoch: 1000, Train Loss: 3.683, Test Loss: 3.478\n",
      "Epoch: 1050, Train Loss: 3.552, Test Loss: 3.549\n",
      "Epoch: 1100, Train Loss: 3.464, Test Loss: 3.776\n",
      "Epoch: 1150, Train Loss: 3.558, Test Loss: 3.801\n",
      "Epoch: 1200, Train Loss: 3.708, Test Loss: 3.824\n",
      "Epoch: 1250, Train Loss: 3.633, Test Loss: 3.740\n",
      "Epoch: 1300, Train Loss: 3.734, Test Loss: 3.372\n",
      "Epoch: 1350, Train Loss: 3.790, Test Loss: 3.198\n",
      "Epoch: 1400, Train Loss: 3.481, Test Loss: 3.488\n",
      "Epoch: 1450, Train Loss: 3.641, Test Loss: 3.579\n",
      "Epoch: 1500, Train Loss: 3.755, Test Loss: 3.506\n",
      "Epoch: 1550, Train Loss: 3.484, Test Loss: 3.654\n",
      "Epoch: 1600, Train Loss: 3.558, Test Loss: 3.198\n",
      "Epoch: 1650, Train Loss: 3.818, Test Loss: 3.512\n",
      "Epoch: 1700, Train Loss: 3.797, Test Loss: 3.581\n",
      "Epoch: 1750, Train Loss: 3.466, Test Loss: 3.534\n",
      "Epoch: 1800, Train Loss: 3.751, Test Loss: 3.527\n",
      "Epoch: 1850, Train Loss: 3.695, Test Loss: 3.669\n",
      "Epoch: 1900, Train Loss: 3.488, Test Loss: 3.178\n",
      "Epoch: 1950, Train Loss: 3.304, Test Loss: 3.446\n",
      "Epoch: 2000, Train Loss: 3.485, Test Loss: 3.367\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    titles, lyrics, targets = get_batch_with_titles(train_tokens, batch_size=batch_size)\n",
    "\n",
    "    y_pred = model((titles, lyrics))\n",
    "    loss = F.cross_entropy(y_pred.view((-1, y_pred.size(-1))), targets.flatten())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % eval_freq == 0 or epoch == 1:\n",
    "        train_loss, test_loss = estimate_loss_with_titles(train_tokens), estimate_loss_with_titles(test_tokens)\n",
    "        print(f\"Epoch: {epoch}, Train Loss: {train_loss:.3f}, Test Loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Like before, we ask the model to generate a sentence, but this time conditioned on a song title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_titles(model: Transformer, title: str, context_size: int = 8, max_length: int = 1000):\n",
    "    pad_token = tokenizer.token_to_id(\"[PAD]\")\n",
    "    title_tokens = torch.tensor(tokenizer.encode(title).ids, device=device)\n",
    "\n",
    "    context = torch.tensor(tokenizer.encode(\"[BOS]\").ids, device=device)\n",
    "    model = model.eval()\n",
    "\n",
    "    for _ in range(max_length):    \n",
    "        max_size = min(max(len(title_tokens), len(context)), context_size)\n",
    "        \n",
    "        context = F.pad(context, pad=(max_size - len(context), 0), mode=\"constant\", value=pad_token)\n",
    "        context = context[-max_size:].unsqueeze(0)\n",
    "\n",
    "        title = F.pad(title_tokens, pad=(max_size - len(title_tokens), 0), mode=\"constant\", value=pad_token)\n",
    "        title = title[-max_size:].unsqueeze(0)\n",
    "        \n",
    "        logits = model((title, context[:, -context_size:]))\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        token = torch.multinomial(probs[:, -1, :].flatten(), num_samples=1).item()\n",
    "\n",
    "        context = torch.cat((context.flatten(), torch.tensor([token], device=device)), dim=0)\n",
    "\n",
    "    model.train()\n",
    "    return tokenizer.decode(context.flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filled drops a call to me have the silver gone , has on the sorted\n",
      "ya gone right shine ll sensation be gloom man tell you have about and labyrin\n",
      "there can time be how black look cleared slight went of ’ s eins strayed\n"
     ]
    }
   ],
   "source": [
    "print(generate_with_titles(model, \"about money\", context_size=config.context_size, max_length=15))\n",
    "print(generate_with_titles(model, \"about life\", context_size=config.context_size, max_length=15))\n",
    "print(generate_with_titles(model, \"about war\", context_size=config.context_size, max_length=15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
